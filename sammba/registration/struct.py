import os
from nipype.interfaces import afni, fsl
from nipype.utils.filemanip import fname_presuffix
from nipype.caching import Memory
from sklearn.utils import deprecated, Bunch
from sammba import segmentation
from ..orientation import fix_obliquity


def anats_to_common(anat_filenames, write_dir, brain_volume,
                    registration_kind='affine',
                    use_rats_tool=True,
                    nonlinear_levels=[1, 2, 3],
                    nonlinear_minimal_patches=[75],
                    nonlinear_weight_file=None,
                    convergence=0.005, blur_radius_coarse=1.1,
                    caching=False, verbose=1,
                    unifize_kwargs=None, brain_masking_unifize_kwargs=None):
    """ Create common template from native anatomical images and achieve
    their registration to it.

    Parameters
    ----------
    anat_filenames : list of str
        Paths to the anatomical images.

    write_dir : str
        Path to an existant directory to save output files to.

    brain_volume : int
        Volume of the brain in mm3 used for brain extraction.
        Typically 400 for mouse and 1800 for rat.

    registration_kind : one of {'rigid', 'affine', 'nonlinear'}, optional
        The allowed transform kind.

    use_rats_tool : bool, optional
        If True, brain mask is computed using RATS Mathematical Morphology.
        Otherwise, a histogram-based brain segmentation is used.

    nonlinear_levels : list of int, optional
        Maximal levels for each nonlinear warping iteration. Passed iteratively
        to nipype.interfaces.afni.Qwarp

    nonlinear_minimal_patches : list of int, optional
        Minimal patches for the final nonlinear warps, passed to
        nipype.interfaces.afni.Qwarp
        
    nonlinear_weight_file : str, optional
        Path to a mask used to weight non-linear registration. Ideally should 
        include not just the whole brain but also extend in all directions to 
        include some amount of surrounding head tissue.
        
    convergence : float, optional
        Convergence limit, passed to nipype.interfaces.afni.Allineate
        
    blur_radius_coarse : float, optional
        Radius passed to nipype.interfaces.afni.Allineate for
        the "-twoblur" option

    caching : bool, optional
        If True, caching is used for all the registration steps.

    verbose : int, optional
        Verbosity level. Note that caching implies some
        verbosity in any case.

    unifize_kwargs : dict, optional
        Is passed to nipype.interfaces.afni.Unifize, to
        control bias correction of the template.

    brain_masking_unifize_kwargs : dict, optional
        Is passed to nipype.interfaces.afni.Unifize, to tune
        the seperate bias correction step done prior to brain masking.

    Returns
    -------
    data : sklearn.utils.Bunch
        Dictionary-like object, the interest attributes are :

        - `registered` : list of str.
                         Paths to registered images. Note that
                         they have undergone a bias correction step before.
        - `transforms` : list of str.
                         Paths to the transforms from the raw
                         images to the registered images.
                         
    Notes
    -----
    nonlinear_weight_file:
    Without this weight mask, for non-linear registration a mask is generated by 
    binarizing the mean of images that have been brain and affine-registered, 
    then evenly dilating it to include some surrounding head tissue. The 
    non-linear registration is then weighted to work only within this mask. This 
    substantially improves performance by 1) reducing the number of voxels to 
    analyse, and 2) avoiding other parts of the head where structures are highly 
    variable and signal often poor. However, this automatically-generated mask 
    is frequently sub-optimal, usually due to missing paraflocculi and 
    inappropriate dilation.
    
    Of course, it is impossible to know ahead of time where to weight the image 
    before the brains/heads have been registered to each other. So in practice a 
    first running of this script is done up until and including the affine stage 
    (the default). The user should then manually use 3dmask_tool or some other 
    software tool to create an intersect/frac/union mask of the 
    _Unifized_for_brain_extraction_masked_resample_shr_affine_catenated files. 
    These can then be dilated as needed to include some surrounding head tissue 
    (which helps to better distinguish the brain-non-brain boundary). Missing 
    regions can be added manually. This does not have to be done precisely, only 
    roughly, and it is better to include too much tissue than too little. The 
    procedure should then be rerun as non-linear, but using this weight mask.                     
    use_rats_tool:
    If `use_rats_tool` is turned on, RATS tool is used for brain extraction
    and has to be cited. For more information, see
    `RATS <http://www.iibi.uiowa.edu/content/rats-overview/>`_
    """
    registration_kinds = ['rigid', 'affine', 'nonlinear']
    if registration_kind not in registration_kinds:
        raise ValueError(
            'Registration kind must be one of {0}, you entered {1}'.format(
                registration_kinds, registration_kind))
                
    if registration_kind is 'nonlinear' and len(anat_filenames) < 5:
        raise ValueError('At least 5 input files are required to make a ' 
                         'template by non-linear \n registration. Only ' 
                         '{0} have been provided.'.format(len(anat_filenames)))

    if use_rats_tool:
        if segmentation.interfaces.Info().version() is None:
            raise ValueError('Can not locate RATS')
        else:
            ComputeMask = segmentation.MathMorphoMask
    else:
        ComputeMask = segmentation.HistogramMask

    if verbose:
        terminal_output = 'stream'
        verbosity_kwargs = {'verbose': verbose > 1}
        quietness_kwargs = {}
        verb_quietness_kwargs = {'verb': verbose > 2}
        verbosity_quietness_kwargs = {'verbose': verbose > 2}
    else:
        terminal_output = 'none'
        verbosity_kwargs = {}
        quietness_kwargs = {'quiet': True}
        verb_quietness_kwargs = {'quiet': True}
        verbosity_quietness_kwargs = {'quiet': True}

    if caching:
        memory = Memory(write_dir)
        copy = memory.cache(afni.Copy)
        unifize = memory.cache(afni.Unifize)
        clip_level = memory.cache(afni.ClipLevel)
        compute_mask = memory.cache(ComputeMask)
        calc = memory.cache(afni.Calc)
        center_mass = memory.cache(afni.CenterMass)
        refit = memory.cache(afni.Refit)
        refit2 = memory.cache(afni.Refit)
        tcat = memory.cache(afni.TCat)
        tstat = memory.cache(afni.TStat)
        undump = memory.cache(afni.Undump)
        resample = memory.cache(afni.Resample)
        allineate = memory.cache(afni.Allineate)
        allineate2 = memory.cache(afni.Allineate)
        mask_tool = memory.cache(afni.MaskTool)
        catmatvec = memory.cache(afni.CatMatvec)
        qwarp = memory.cache(afni.Qwarp)
        qwarp2 = memory.cache(afni.Qwarp)  # workaround to initialize inputs
        nwarp_adjust = memory.cache(afni.NwarpAdjust)
        nwarp_cat = memory.cache(afni.NwarpCat)
        warp_apply = memory.cache(afni.NwarpApply)
        for step in [copy, unifize, calc, refit, refit2,
                     tcat, tstat, undump, resample, allineate, allineate2,
                     mask_tool, catmatvec, qwarp, nwarp_cat, warp_apply,
                     nwarp_adjust]:
            step.interface().set_default_terminal_output(terminal_output)
    else:
        copy = afni.Copy(terminal_output=terminal_output).run
        unifize = afni.Unifize(terminal_output=terminal_output).run
        clip_level = afni.ClipLevel().run  # XXX fix nipype bug with 'none'
        compute_mask = ComputeMask().run
        calc = afni.Calc(terminal_output=terminal_output).run
        center_mass = afni.CenterMass().run  # XXX fix nipype bug with 'none'
        refit = afni.Refit(terminal_output=terminal_output).run
        refit2 = afni.Refit(terminal_output=terminal_output).run
        tcat = afni.TCat(terminal_output=terminal_output).run
        tstat = afni.TStat(terminal_output=terminal_output).run
        undump = afni.Undump(terminal_output=terminal_output).run
        resample = afni.Resample(terminal_output=terminal_output).run
        allineate = afni.Allineate(terminal_output=terminal_output).run
        allineate2 = afni.Allineate(terminal_output=terminal_output).run
        mask_tool = afni.MaskTool(terminal_output=terminal_output).run
        catmatvec = afni.CatMatvec(terminal_output=terminal_output).run
        qwarp = afni.Qwarp(terminal_output=terminal_output).run
        qwarp2 = afni.Qwarp(terminal_output=terminal_output).run
        nwarp_cat = afni.NwarpCat(terminal_output=terminal_output).run
        warp_apply = afni.NwarpApply(terminal_output=terminal_output).run
        nwarp_adjust = afni.NwarpAdjust(terminal_output=terminal_output).run

    current_dir = os.getcwd()
    os.chdir(write_dir)

    ###########################################################################
    # First copy anatomical files to make sure the originals are never changed
    # and they have different names across individuals. Then produce a video of
    # this raw data and a mean
    copied_anat_filenames = []
    for n, anat_file in enumerate(anat_filenames):
        suffixed_file = fname_presuffix(anat_file, suffix='_{}'.format(n))
        out_file = os.path.join(write_dir, os.path.basename(suffixed_file))
        out_copy = copy(in_file=anat_file, out_file=out_file,
                        **verbosity_kwargs)
        copied_anat_filenames.append(out_copy.outputs.out_file)


    out_tcat = tcat(in_files=copied_anat_filenames,
                    out_file=os.path.join(write_dir, 'raw_heads.nii.gz'),
                    outputtype='NIFTI_GZ', **verbosity_kwargs)
    out_tstat = tstat(in_file=out_tcat.outputs.out_file, outputtype='NIFTI_GZ')

    ###########################################################################
    # Bias correct and register using center of mass
    # -----------------------------
    # An initial coarse registration is done using brain centre of mass (CoM).
    #
    # First we loop through anatomical scans and correct intensities for bias. 
    # This is done twice with parameters that can be set differently: once to 
    # create an image for automatic brain mask generation, and a another time 
    # for the image that will actually have its brain extracted by this mask and 
    # also be passed on to the rest of the function. This separation is useful
    # because in some circumstances the ideal bias correction can create zones 
    # of signal and noise that confuse the brain masker, so it is best if that 
    # calculation is performed on a differently-corrected image. In a lot(most?) 
    # cases, the same parameters can be used for both bias correctors (the 
    # default) as though the correction was only ever done once.
    #
    # Second, image centers are redefined based on the CoM of brains extracted 
    # by the brain masks. The images are then translated to force the new 
    # centers to all be at the same position: the center of the image matrix. 
    # This is a crude form of translation-only registration amongst images that 
    # simultaneously shifts the position of all brains to being in the centre of 
    # the image if this was not already the case (which it often is not in small 
    # mammal head imaging where the brain is usually in the upper half).
    #
    # Note that the heads created at the end will be the start point for all 
    # subsequent transformations (meaning any transformation generated from now
    # on will be a concatenation of itself and previous ones for direct 
    # application to CoM-registered heads). This avoids the accumulation of 
    # reslice error from one registration to the next. Ideally, the start point 
    # should be the bias-corrected images prior to center correction (which 
    # itself involes reslicing). However, I have not yet figured out the best 
    # way to convert CoM change into an affine transform and then use it. The 
    # conversion should be relatively easy, using nibabel to extract the two 
    # affines then numpy to calculate the difference. Using it is not so simple. 
    # Unlike 3dQwarp, 3dAllineate does not have a simple initialization flag. 
    # Instead, it is necessary to use -parini to initialize any given affine 
    # parameter individually. However, -parini can be overidden by other flags, 
    # so careful checks need to be made to ensure that this will never happen 
    # with the particular command or set of commands used here.
    
    # bias correction for images to be used for brain mask creation
    if brain_masking_unifize_kwargs is None:
        brain_masking_unifize_kwargs = {}
    brain_masking_unifize_kwargs.update(quietness_kwargs)
    brain_masking_in_files = []
    for n, anat_file in enumerate(copied_anat_filenames):
        out_unifize = unifize(in_file=anat_file,
                              out_file='%s_Unifized_for_brain_masking',
                              outputtype='NIFTI_GZ',
                              **brain_masking_unifize_kwargs)
        brain_masking_in_files.append(out_unifize.outputs.out_file)

    # brain mask creation
    brain_mask_files = []
    for n, brain_masking_in_file in enumerate(brain_masking_in_files):
        out_clip_level = clip_level(in_file=brain_masking_in_file)
        out_compute_mask = compute_mask(
            in_file=brain_masking_in_file,
            out_file=fname_presuffix(brain_masking_in_file, suffix='_mask'),
            volume_threshold=brain_volume,
            intensity_threshold=int(out_clip_level.outputs.clip_val))
        brain_mask_files.append(out_compute_mask.outputs.out_file)

    # bias correction for images to be both brain-extracted with the mask 
    # generated above and then passed on to the rest of the function
    if unifize_kwargs is None:
        unifize_kwargs = {}

    unifize_kwargs.update(quietness_kwargs)
    unifized_files = []
    for n, anat_file in enumerate(copied_anat_filenames):
        out_unifize = unifize(in_file=anat_file,
                              out_file='%s_Unifized_for_brain_extraction',
                              outputtype='NIFTI_GZ',
                              **unifize_kwargs)
        unifized_files.append(out_unifize.outputs.out_file)

    # extrcat brains and set NIfTI image center (as defined in the header) to 
    # the brain CoM
    brain_files = []
    for (brain_mask_file, unifized_file) in zip(brain_mask_files,
                                                unifized_files):
        out_calc_mask = calc(in_file_a=unifized_file,
                             in_file_b=brain_mask_file,
                             expr='a*b',
                             outputtype='NIFTI_GZ')
        out_center_mass = center_mass(
            in_file=out_calc_mask.outputs.out_file,
            cm_file=fname_presuffix(unifized_file, suffix='_cm.txt',
                                    use_ext=False),
            set_cm=(0, 0, 0))
        brain_files.append(out_center_mass.outputs.out_file)

    # apply center change to head files too
    head_files = []    
    for unifized_file, brain_file in zip(unifized_files, brain_files):
        out_refit = refit(in_file=unifized_file, duporigin_file=brain_file)
        head_files.append(out_refit.outputs.out_file)

    # create an empty template with a center at the image matrix center
    out_undump = undump(in_file=out_tstat.outputs.out_file,
                        out_file=os.path.join(write_dir, 'undump.nii.gz'),
                        outputtype='NIFTI_GZ')
    out_refit = refit2(in_file=out_undump.outputs.out_file,
                       xorigin='cen', yorigin='cen', zorigin='cen')

    # shift brains to place their new centers at the same central position. 
    # make a quality check video and mean
    centered_brain_files = []
    for brain_file in brain_files:
        out_resample = resample(in_file=brain_file,
                                resample_mode='Cu',
                                master=out_refit.outputs.out_file,
                                outputtype='NIFTI_GZ')
        centered_brain_files.append(out_resample.outputs.out_file)
    out_tcat = tcat(in_files=centered_brain_files,
                    out_file=os.path.join(write_dir, 'centered_brains.nii.gz'),
                    **verbosity_kwargs)
    out_tstat_centered_brain = tstat(in_file=out_tcat.outputs.out_file,
                                     outputtype='NIFTI_GZ')
    
    # do the same for heads. is also a better quality check than the brain
    centered_head_files = []
    for head_file in head_files:
        out_resample = resample(in_file=head_file,
                                resample_mode='Cu',
                                master=out_refit.outputs.out_file,
                                outputtype='NIFTI_GZ')
        centered_head_files.append(out_resample.outputs.out_file)
    out_tcat = tcat(in_files=centered_head_files,
                    out_file=os.path.join(write_dir, 'centered_heads.nii.gz'),
                    **verbosity_kwargs)
    out_tstat_centered_brain = tstat(in_file=out_tcat.outputs.out_file,
                                     outputtype='NIFTI_GZ')

    ###########################################################################
    # At this point, we have achieved a translation-only registration of the 
    # anatomical images to each other's brain's (as defined by the brain
    # masker) CoMs.
    ###########################################################################
    # Rigid-body registration (shift rotate in AFNI parlance)
    # -------------------------------------------------------
    # Now we move on to the rigid-body registration of CoM brains, and 
    # application of this registration to CoM heads. This requires a target
    # template. Here we use the mean of all bias-corrected, brain-extracted,
    # mass-centered images. Other possibilities include an externally-sourced
    # image or, more biased, a nicely-aligned individual.
    # 
    # In extreme cases where acquisitions were done at highly variable head 
    # angles, it may be worth running this twice or even more (for which there 
    # is no current functionality), but we have never found a case that extreme 
    # so it is not implemented.
    
    # rigid-body registration
    shift_rotated_brain_files = []
    rigid_transform_files = []
    for centered_brain_file in centered_brain_files:
        suffixed_matrix = fname_presuffix(centered_brain_file,
                                          suffix='_shr.aff12.1D',
                                          use_ext=False)
        out_matrix = os.path.join(write_dir, os.path.basename(suffixed_matrix))
        out_allineate = allineate(
            in_file=centered_brain_file,
            reference=out_tstat_centered_brain.outputs.out_file,
            out_matrix=out_matrix,
            convergence=convergence,
            two_blur=blur_radius_coarse,
            warp_type='shift_rotate',
            out_file=fname_presuffix(centered_brain_file, suffix='_shr'),
            **verbosity_quietness_kwargs)
        rigid_transform_files.append(out_allineate.outputs.out_matrix)
        shift_rotated_brain_files.append(out_allineate.outputs.out_file)

    # application to the head images
    shift_rotated_head_files = []
    for centered_head_file, rigid_transform_file in zip(centered_head_files,
                                                        rigid_transform_files):
        suffixed_file = fname_presuffix(centered_head_file, suffix='_shr')
        out_file = os.path.join(write_dir, os.path.basename(suffixed_file))
        out_allineate = allineate2(
            in_file=centered_head_file,
            master=out_tstat_centered_brain.outputs.out_file,
            in_matrix=rigid_transform_file,
            out_file=out_file,
            **verbosity_quietness_kwargs)
        shift_rotated_head_files.append(out_allineate.outputs.out_file)

    # quality check video and mean for head and brain
    out_tcat = tcat(
        in_files=shift_rotated_head_files,
        out_file=os.path.join(write_dir, 'rigid_body_registered_heads.nii.gz'),
        **verbosity_kwargs)
    out_tstat_shr = tstat(in_file=out_tcat.outputs.out_file,
                          outputtype='NIFTI_GZ')
    out_tcat = tcat(
        in_files=shift_rotated_brain_files,
        out_file=os.path.join(write_dir, 'rigid_body_registered_brains.nii.gz'),
        **verbosity_kwargs)
    out_tstat_shr = tstat(in_file=out_tcat.outputs.out_file,
                          outputtype='NIFTI_GZ')

    if registration_kind == 'rigid':
        os.chdir(current_dir)
        return Bunch(registered=shift_rotated_head_files,
                     transforms=rigid_transform_files)

    ###########################################################################
    # Affine transform
    # ----------------
    # Similar to the previous rigid-body registration but with the following
    # differences:
    # 1) The registration target is now the product of rigid-body rather than
    #    CoM registration.
    # 2) Rather than using the mean brain as a target, the mean head is used, 
    #    weighted by a mask made by binarizing the brains and making a count 
    #    mask out of them. This should mathematically be exactly the same thing 
    #    and was done this way partially for fun, partially to make more use of 
    #    the count mask, whose main purpose is to demonstrate variability in 
    #    brain size and extraction quality.
    # 3) There is an extra step for concatenation of transform results.
    
    # make the count mask
    out_mask_tool = mask_tool(in_file=out_tcat.outputs.out_file,
                              count=True,
                              verbose=verbose,
                              outputtype='NIFTI_GZ')

    #affine transform
    affine_transform_files = []
    for shift_rotated_head_file, rigid_transform_file in zip(
            shift_rotated_head_files, rigid_transform_files):
        out_allineate = allineate(
            in_file=shift_rotated_head_file,
            reference=out_tstat_shr.outputs.out_file,
            out_matrix=fname_presuffix(shift_rotated_head_file,
                                       suffix='_affine.aff12.1D',
                                       use_ext=False),
            convergence=convergence,
            two_blur=blur_radius_coarse,
            one_pass=True,
            weight=out_mask_tool.outputs.out_file,
            out_file=fname_presuffix(shift_rotated_head_file,
                                     suffix='_affine'),
            **verbosity_quietness_kwargs)
        # matrix concatenation
        suffixed_matrix = fname_presuffix(shift_rotated_head_file,
                                          suffix='_affine_catenated.aff12.1D',
                                          use_ext=False)
        catmatvec_out_file = os.path.join(write_dir,
                                          os.path.basename(suffixed_matrix))
        out_catmatvec = catmatvec(in_file=[(rigid_transform_file, 'ONELINE'),
                                           (out_allineate.outputs.out_matrix,
                                            'ONELINE')],
                                  out_file=catmatvec_out_file)
        affine_transform_files.append(out_catmatvec.outputs.out_file)

    # application to brains
    allineated_brain_files = []
    for centered_brain_file, affine_transform_file in zip(
            centered_brain_files, affine_transform_files):
        out_allineate = allineate2(
            in_file=centered_brain_file,
            master=out_tstat_shr.outputs.out_file,
            in_matrix=affine_transform_file,
            out_file=fname_presuffix(centered_brain_file,
                                     suffix='_shr_affine_catenated'),
            **verbosity_quietness_kwargs)
        allineated_brain_files.append(out_allineate.outputs.out_file)

    # application to heads
    allineated_head_files = []
    for centered_head_file, affine_transform_file in zip(
            centered_head_files, affine_transform_files):
        suffixed_file = fname_presuffix(centered_head_file,
                                        suffix='_shr_affine_catenated')
        out_file = os.path.join(write_dir, os.path.basename(suffixed_file))
        out_allineate = allineate2(
            in_file=centered_head_file,
            master=out_tstat_shr.outputs.out_file,
            in_matrix=affine_transform_file,
            out_file=out_file,
            **verbosity_quietness_kwargs)
        allineated_head_files.append(out_allineate.outputs.out_file)

    #quality check videos and template for head and brain
    out_tcat_head = tcat(
        in_files=allineated_head_files,
        out_file=os.path.join(write_dir, 'affine_registered_heads.nii.gz'),
        **verbosity_kwargs)
    out_tstat_allineated_head = tstat(in_file=out_tcat_head.outputs.out_file,
                                      outputtype='NIFTI_GZ')
    out_tcat_brain = tcat(
        in_files=allineated_brain_files,
        out_file=os.path.join(write_dir, 'affine_registered_brains.nii.gz'),
        **verbosity_kwargs)
    out_tstat_allineated_brain = tstat(in_file=out_tcat_brain.outputs.out_file,
                                       outputtype='NIFTI_GZ')

    if registration_kind == 'affine':
        os.chdir(current_dir)
        return Bunch(registered=allineated_head_files,
                     transforms=affine_transform_files)

    ###########################################################################
    # Non-linear registration
    # -----------------------
    # A weight mask that extends beyond the brain, incorporating some
    # surrounding tissue, is needed to help better define the brain head
    # boundary.
    if nonlinear_weight_file is None:
        out_mask_tool = mask_tool(
            in_file=out_tcat.outputs.out_file,
            union=True,
            out_file=os.path.join(
                write_dir,
                'affine_registered_brains_unionmask.nii.gz'),
            outputtype='NIFTI_GZ',
            verbose=verbose)
        out_mask_tool = mask_tool(
            in_file=out_mask_tool.outputs.out_file,
            out_file=os.path.join(
                write_dir,
                'affine_registered_brains_unionmask_dil4.nii.gz'),
            dilate_inputs='4',
            outputtype='NIFTI_GZ',
            verbose=verbose)
        nonlinear_weight_file = out_mask_tool.outputs.out_file

    ###########################################################################
    # Successive cycles of non-linear registration are executed.
    # The non-linear registration uses the AFNI tool 3dQwarp, which repeatedly
    # composes incremental warps defined by Hermite cubic basis functions,
    # first over the entire volume, then over steadily shrinking
    # and overlapping patches, with the resulting final warp being a grid
    # representation of a diffeomorphism between source and target images.
    # We choose the final patch size relatively large in the first cycle
    # and substantially reduce it with each subsequent cycle. The intermediate
    # and final templates are all means in intensity space of transformed
    # images.
    # 
    if nonlinear_levels is None:
        nonlinear_levels = [1, 2, 3]

    for n_lev, maxlev in enumerate(nonlinear_levels):        
        if n_lev == 0:
            inilev = 0
            # first cycle registers the centered heads to the affine template
            common_head_file = out_tstat_allineated_head.outputs.out_file
            # Transform the affine transforms to warps for initializing
            # the first cycle non-linear registration
            previous_warp_files = []
            for affine_file, centered_head_file in zip(affine_transform_files, 
                                                       centered_head_files):
                out_nwarp_cat = nwarp_cat(
                    in_files=[('IDENT', centered_head_file), affine_file],
                    out_file=fname_presuffix(centered_head_file,
                                             suffix='_iniwarp'))
                previous_warp_files.append(out_nwarp_cat.outputs.out_file)

        warped_files = []
        warp_files = []
        for warp_file, centered_head_file in zip(previous_warp_files, 
                                                 centered_head_files):
            out_file = fname_presuffix(centered_head_file,
                                       suffix='_warped{}'.format(n_lev))
            out_qwarp = qwarp(
                in_file=centered_head_file,
                base_file=common_head_file,
                noneg=True,
                iwarp=True,
                weight=nonlinear_weight_file,
                iniwarp=[warp_file],
                inilev=inilev,
                maxlev=maxlev,
                out_file=out_file,
                **verb_quietness_kwargs)
            warped_files.append(out_qwarp.outputs.warped_source)
            # Collect the current warps to initialize the transforms of
            # the next non-linear cycle
            warp_files.append(out_qwarp.outputs.source_warp)
            previous_warp_files = warp_files

        inilev = maxlev + 1
        # Compute the average of the warped images while accounting
        # for systematic biases in the non-linear transforms
        common_head_file = os.path.join(
                write_dir, 'warped_{0}_adjusted_mean.nii.gz'.format(n_lev))
        out_nwarp_adjust = nwarp_adjust(warps=warp_files,
                                        in_files=centered_head_files,
                                        out_file=common_head_file)                            

    if nonlinear_levels == []:
        previous_warp_files = affine_transform_files
        inilev = 0
        n_lev = 0
    else:
        inilev = maxlev + 1    # not ideal
  
    if nonlinear_minimal_patches is None:
       nonlinear_minimal_patches = []
       n_iter = n_lev

    for n_patch, minpatch in enumerate(nonlinear_minimal_patches):        
        warped_files = []
        warp_files = []
        n_iter = n_lev + n_patch
        for warp_file, centered_head_file in zip(previous_warp_files, 
                                                 centered_head_files):            
            out_file = fname_presuffix(centered_head_file,
                                       suffix='_warped{}'.format(n_iter))
            out_qwarp = qwarp2(
                in_file=centered_head_file,
                base_file=common_head_file,
                noneg=True,
                iwarp=True,
                weight=nonlinear_weight_file,
                iniwarp=[warp_file],
                inilev=inilev,
                minpatch=minpatch,
                out_file=out_file,
                **verb_quietness_kwargs)
                    
            warped_files.append(out_qwarp.outputs.warped_source)
            warp_files.append(out_qwarp.outputs.source_warp)
            previous_warp_files = warp_files

        out_tcat = tcat(
            in_files=warped_files,
            out_file=os.path.join(
                write_dir,
                'warped_{0}iters_template.nii.gz'.format(n_iter)),
            **verbosity_kwargs)
        out_tstat_warp_head = tstat(in_file=out_tcat.outputs.out_file,
                                    outputtype='NIFTI_GZ')

        common_head_file = os.path.join(
                write_dir, 'warped_{0}_adjusted_mean.nii.gz'.format(n_iter))
        out_nwarp_adjust = nwarp_adjust(warps=warp_files,
                                        in_files=centered_head_files,
                                        out_file=common_head_file)                            
                                    
    ###########################################################################
    # Register to template
    # --------------------
    # Apply non-linear registration results to uncorrected images
    # XXX has already been computed !
    warped_files = []
    for centered_head_file, warp_file in zip(centered_head_files, warp_files):
        suffixed_file = fname_presuffix(
            centered_head_file,
            suffix='affine_warp{}_catenated'.format(len(nonlinear_levels)))
        out_file = os.path.join(write_dir, os.path.basename(suffixed_file))
        out_warp_apply = warp_apply(
            in_file=centered_head_file,
            warp=warp_file,
            master=out_tstat_warp_head.outputs.out_file,
            out_file=out_file,
            **verb_quietness_kwargs)
        warped_files.append(out_warp_apply.outputs.out_file)

    os.chdir(current_dir)
    return Bunch(registered=warped_files,
                 transforms=warp_files)


def anat_to_template(anat_filename, brain_filename,
                     head_template_filename,
                     brain_template_filename, write_dir=None,
                     dilated_head_mask_filename=None, convergence=.005,
                     maxlev=None,
                     caching=False, verbose=1, environ=None,
                     registration_kind='nonlinear'):
    """ Registers an unbiased anatomical image to a given template.
    Parameters
    ----------
    anat_filename : str
        Paths to the head image to register.
    brain_filename : str
        Paths to the brain extracted image.
    head_template_filename : str
        Path to the head template.
    brain_template_filename : str
        Path to the brain extracted template.
    write_dir : str, optional
        Path to an existant directory to save output files to. If None, the
        current directory is used.
    dilated_head_mask_filename : str, optional
        Path to a dilated head mask. Note that this must be compliant with the
        the given head template. If None, the mask is set to the non-background
        voxels of the head template after one dilation.
    caching : bool, optional
        If True, caching is used for all the registration steps.
    convergence : float, optional
        Convergence limit, passed to
        nipype.interfaces.afni.Allineate
    maxlev : int or None, optional
        If not None, maximal level for the nonlinear warping. Passed to
        nipype.interfaces.afni.Qwarp.
        Lower implies faster but possibly lower precision.
    verbose : int, optional
        Verbosity level. Note that caching implies some
        verbosity in any case.
    unifize_kwargs : dict, optional
        Is passed to nipype.interfaces.afni.Unifize, to
        control bias correction of the template.
    Returns
    -------
    data : sklearn.utils.Bunch
        Dictionary-like object, the interest attributes are :
        - `registered` : str.
                         Path to registered image.
        - `pre_transform` : str.
                            Paths to the affine transform from the native
                            image to the images affine allineated to the
                            template.
        - `transform` : str.
                        Paths to the warp transform from the allineated
                        image to the final registered image.
    Note
    ----
    Please note that if the template was made with bias corrected images,
    then the anatomical image should also be processed the same way for better
    results. This dictum applies in general: the template and anatomical images
    should be pre-processed the same way, as far as practicable.
    """
    registration_kinds = ['rigid', 'affine', 'nonlinear']
    if registration_kind not in registration_kinds:
        raise ValueError(
            'Registration kind must be one of {0}, you entered {1}'.format(
                registration_kinds, registration_kind))

    if environ is None:
        environ = {'AFNI_DECONFLICT': 'OVERWRITE'}
    if verbose:
        terminal_output = 'stream'
        verb_quietness_kwargs = {'verb': verbose > 2}
        verbosity_quietness_kwargs = {'verbose': verbose > 2}
    else:
        terminal_output = 'none'
        verb_quietness_kwargs = {'quiet': True}
        verbosity_quietness_kwargs = {'quiet': True}

    if write_dir is None:
        write_dir = os.path.dirname(anat_filename)

    if caching:
        memory = Memory(write_dir)
        clip_level = memory.cache(afni.ClipLevel)
        threshold = memory.cache(fsl.Threshold)
        mask_tool = memory.cache(afni.MaskTool)
        allineate = memory.cache(afni.Allineate)
        allineate_apply = memory.cache(afni.Allineate)
        qwarp = memory.cache(afni.Qwarp)
        for step in [allineate, allineate_apply, threshold, mask_tool, qwarp]:
            step.interface().set_default_terminal_output(terminal_output)
    else:
        clip_level = afni.ClipLevel().run
        threshold = fsl.Threshold(terminal_output=terminal_output).run
        mask_tool = afni.MaskTool(terminal_output=terminal_output).run
        allineate = afni.Allineate(terminal_output=terminal_output).run
        allineate_apply = afni.Allineate(terminal_output=terminal_output).run
        qwarp = afni.Qwarp(terminal_output=terminal_output).run

    intermediate_files = []
    if dilated_head_mask_filename is None:
        out_clip_level = clip_level(in_file=head_template_filename)
        out_threshold = threshold(
            in_file=head_template_filename,
            thresh=out_clip_level.outputs.clip_val,
            out_file=fname_presuffix(head_template_filename,
                                     suffix='_thresholded', newpath=write_dir))
        out_mask_tool = mask_tool(in_file=out_threshold.outputs.out_file,
                                  dilate_inputs='3',
                                  outputtype='NIFTI_GZ',
                                  environ=environ,
                                  verbose=verbose)
        dilated_head_mask_filename = out_mask_tool.outputs.out_file
        intermediate_files.append(out_threshold.outputs.out_file)

    # the actual T1anat to template registration using the brain extracted
    # image could do in one 3dQwarp step using allineate flags but will
    # separate as 3dAllineate performs well on brain image, and 3dQwarp
    # well on whole head
    affine_transform_filename = fname_presuffix(brain_filename,
                                                suffix='_aff.aff12.1D',
                                                use_ext=False,
                                                newpath=write_dir)
    out_allineate = allineate(
        in_file=brain_filename,
        reference=brain_template_filename,
        master=brain_template_filename,
        out_matrix=affine_transform_filename,
        two_blur=convergence * 11. / .05,
        cost='nmi',
        convergence=convergence,
        two_pass=True,
        center_of_mass='',
        maxrot=90,
        out_file=fname_presuffix(brain_filename, suffix='_aff',
                                 newpath=write_dir),
        environ=environ,
        **verbosity_quietness_kwargs)
    intermediate_files.append(out_allineate.outputs.out_file)

    # Apply the registration to the whole head
    out_allineate_apply = allineate_apply(
        in_file=anat_filename,
        master=head_template_filename,
        in_matrix=affine_transform_filename,
        out_file=fname_presuffix(anat_filename, suffix='_affine_general',
                                 newpath=write_dir),
        environ=environ,
        **verbosity_quietness_kwargs)
    allineated_filename = out_allineate_apply.outputs.out_file

    # Non-linear registration of affine pre-registered whole head image
    # to template. Don't initiate straight from the original with an
    # iniwarp due to weird errors (like it creating an Allin it then can't
    # find)
    if registration_kind != 'nonlinear':
        registered = fix_obliquity(allineated_filename, head_template_filename,
                                   caching=caching,
                                   caching_dir=write_dir, environ=environ)
        warp_transform = None
    else:
        intermediate_files.extend(allineated_filename)
        if maxlev is not None:
            out_qwarp = qwarp(
                in_file=allineated_filename,
                base_file=head_template_filename,
                weight=dilated_head_mask_filename,
                nmi=True,
                noneg=True,
                blur=[0],
                maxlev=maxlev,
                out_file=fname_presuffix(allineated_filename, suffix='_warped'),
                environ=environ,
                **verb_quietness_kwargs)
        else:
            out_qwarp = qwarp(
                in_file=allineated_filename,
                base_file=head_template_filename,
                weight=dilated_head_mask_filename,
                nmi=True,
                noneg=True,
                blur=[0],
                out_file=fname_presuffix(allineated_filename, suffix='_warped'),
                environ=environ,
                **verb_quietness_kwargs)
        registered = fix_obliquity(out_qwarp.outputs.warped_source,
                                   head_template_filename,
                                   caching=caching,
                                   caching_dir=write_dir, environ=environ)
        warp_transform = out_qwarp.outputs.source_warp

    if not caching:
        for intermediate_file in intermediate_files:
            if os.path.isfile(intermediate_file):
                os.remove(intermediate_file)

    return Bunch(registered=registered,
                 transform=warp_transform,
                 pretransform=affine_transform_filename)


@deprecated("Function 'anats_to_template' has been replaced by "
            "function 'anat_to_template' and will be "
            "removed in future release. ")
def anats_to_template(anat_filenames, head_template_filename, write_dir,
                      brain_volume, use_rats_tool=True,
                      registration_kind='nonlinear',
                      brain_template_filename=None,
                      dilated_head_mask_filename=None, convergence=.005,
                      maxlev=None,
                      caching=False, verbose=1, unifize_kwargs=None,
                      brain_masking_unifize_kwargs=None):
    """ Registers raw anatomical images to a given template.

    Parameters
    ----------
    anat_filenames : list of str
        Paths to the anatomical images.

    head_template_filename : str
        Path to the head template.

    write_dir : str
        Path to an existant directory to save output files to.

    brain_volume : int
        Volume of the brain in mm3 used for brain extraction.
        Typically 400 for mouse and 1800 for rat.

    use_rats_tool : bool, optional
        If True, brain mask is computed using RATS Mathematical Morphology.
        Otherwise, a histogram-based brain segmentation is used.

    registration_kind : one of {'rigid', 'affine', 'nonlinear'}, optional
        The allowed transform kind.

    brain_template_filename : str, optional
        Path to a brain template. Note that this must coincide with the brain
        from the given head template. If None, the brain is extracted from
        the template with RATS.

    dilated_head_mask_filename : str, optional
        Path to a dilated head mask. Note that this must be compliant with the
        the given head template. If None, the mask is set to the non-background
        voxels of the head template after one dilation.

    caching : bool, optional
        If True, caching is used for all the registration steps.

    convergence : float, optional
        Convergence limit, passed to
        nipype.interfaces.afni.Allineate

    maxlev : int or None, optional
        If not None, maximal level for the nonlinear warping. Passed to
        nipype.interfaces.afni.Qwarp.
        Lower implies faster but possibly lower precision.

    verbose : int, optional
        Verbosity level. Note that caching implies some
        verbosity in any case.

    unifize_kwargs : dict, optional
        Is passed to nipype.interfaces.afni.Unifize, to
        control bias correction of the template.

    brain_masking_unifize_kwargs : dict, optional
        Is passed to nipype.interfaces.afni.Unifize, to tune
        the seperate bias correction step done prior to brain extraction.

    Returns
    -------
    data : sklearn.utils.Bunch
        Dictionary-like object, the interest attributes are :

        - `registered` : list of str.
                         Paths to registered images. Note that
                         they have undergone a bias correction step before.
        - `pre_transforms` : list of str.
                             Paths to the affine transforms from the raw
                             images to the images allineated to the template.
        - `transforms` : list of str.
                         Paths to the transforms from the allineated
                         images to the final registered images.

    Notes
    -----
    If `use_rats_tool` is turned on, RATS tool is used for brain extraction
    and has to be cited. For more information, see
    `RATS <http://www.iibi.uiowa.edu/content/rats-overview/>`_
    """
    registration_kinds = ['rigid', 'affine', 'nonlinear']
    if registration_kind not in registration_kinds:
        raise ValueError(
            'Registration kind must be one of {0}, you entered {1}'.format(
                registration_kinds, registration_kind))
    environ = {}
    if verbose:
        terminal_output = 'stream'
        quietness_kwargs = {}
        verb_quietness_kwargs = {'verb': verbose > 2}
        verbosity_quietness_kwargs = {'verbose': verbose > 2}
    else:
        terminal_output = 'none'
        quietness_kwargs = {'quiet': True}
        verb_quietness_kwargs = {'quiet': True}
        verbosity_quietness_kwargs = {'quiet': True}

    if use_rats_tool:
        if segmentation.interfaces.Info().version() is None:
            raise ValueError('Can not locate RATS')
        else:
            ComputeMask = segmentation.MathMorphoMask
    else:
        ComputeMask = segmentation.HistogramMask

    if caching:
        memory = Memory(write_dir)
        clip_level = memory.cache(afni.ClipLevel)
        compute_mask = memory.cache(ComputeMask)
        calc = memory.cache(afni.Calc)
        mask_tool = memory.cache(afni.MaskTool)
        allineate = memory.cache(afni.Allineate)
        allineate2 = memory.cache(afni.Allineate)
        unifize = memory.cache(afni.Unifize)
        qwarp = memory.cache(afni.Qwarp)
        for step in [allineate, allineate2, calc,
                     mask_tool, unifize, qwarp]:
            step.interface().set_default_terminal_output(terminal_output)
    else:
        unifize = afni.Unifize(terminal_output=terminal_output).run
        clip_level = afni.ClipLevel().run
        compute_mask = ComputeMask().run
        calc = afni.Calc(terminal_output=terminal_output).run
        mask_tool = afni.MaskTool(terminal_output=terminal_output).run
        allineate = afni.Allineate(terminal_output=terminal_output).run
        allineate2 = afni.Allineate(terminal_output=terminal_output).run  # TODO: remove after fixed bug
        qwarp = afni.Qwarp(terminal_output=terminal_output).run
        environ['AFNI_DECONFLICT'] = 'OVERWRITE'

    current_dir = os.getcwd()
    os.chdir(write_dir)
    intermediate_files = []
    if brain_template_filename is None:
        out_clip_level = clip_level(in_file=head_template_filename)
        out_rats = compute_mask(
            in_file=head_template_filename,
            volume_threshold=brain_volume,
            intensity_threshold=int(out_clip_level.outputs.clip_val))
        out_calc_mask = calc(in_file_a=head_template_filename,
                             in_file_b=out_rats.outputs.out_file,
                             expr='a*b',
                             outputtype='NIFTI_GZ')
        brain_template_filename = out_calc_mask.outputs.out_file

    if dilated_head_mask_filename is None:
        out_clip_level = clip_level(in_file=head_template_filename)
        out_calc_threshold = calc(
            in_file_a=head_template_filename,
            expr='ispositive(a-{0})*a'.format(out_clip_level.outputs.clip_val),
            outputtype='NIFTI_GZ')
        out_mask_tool = mask_tool(in_file=out_calc_threshold.outputs.out_file,
                                  dilate_inputs='3',
                                  outputtype='NIFTI_GZ',
                                  environ=environ,
                                  verbose=verbose)
        dilated_head_mask_filename = out_mask_tool.outputs.out_file
        intermediate_files.append(out_calc_threshold.outputs.out_file)

    if brain_masking_unifize_kwargs is None:
        brain_masking_unifize_kwargs = {}

    brain_masking_unifize_kwargs.update(quietness_kwargs)

    brain_extraction_in_files = []
    for anat_filename in anat_filenames:
        out_unifize = unifize(in_file=anat_filename, outputtype='NIFTI_GZ',
                              environ=environ,
                              **brain_masking_unifize_kwargs)
        brain_extraction_in_files.append(out_unifize.outputs.out_file)

    brain_mask_files = []
    for brain_extraction_in_file in brain_extraction_in_files:
        out_clip_level = clip_level(in_file=brain_extraction_in_file)
        out_rats = compute_mask(
            in_file=brain_extraction_in_file,
            volume_threshold=brain_volume,
            intensity_threshold=int(out_clip_level.outputs.clip_val))
        brain_mask_files.append(out_rats.outputs.out_file)

    if unifize_kwargs is None:
        unifize_kwargs = {}
    unifize_kwargs.update(quietness_kwargs)

    unbiased_anat_filenames = []
    for anat_filename in anat_filenames:
        out_unifize = unifize(in_file=anat_filename, environ=environ,
                              urad=18.3, outputtype='NIFTI_GZ',
                              **unifize_kwargs)
        unbiased_anat_filenames.append(out_unifize.outputs.out_file)

    if registration_kind == 'rigid':
        warp_type = 'shift_rotate'
    else:
        warp_type = 'affine_general'

    affine_transforms = []
    allineated_filenames = []
    for (unbiased_anat_filename,
         brain_mask_file) in zip(unbiased_anat_filenames,
                                 brain_mask_files):
        out_calc_mask = calc(in_file_a=unbiased_anat_filename,
                             in_file_b=brain_mask_file,
                             expr='a*b',
                             outputtype='NIFTI_GZ')
        masked_anat_filename = out_calc_mask.outputs.out_file

        # the actual T1anat to template registration using the brain extracted
        # image could do in one 3dQwarp step using allineate flags but will
        # separate as 3dAllineate performs well on brain image, and 3dQwarp
        # well on whole head
        affine_transform_filename = fname_presuffix(masked_anat_filename,
                                                    suffix='_aff.aff12.1D',
                                                    use_ext=False)
        out_allineate = allineate(
            in_file=masked_anat_filename,
            reference=brain_template_filename,
            master=brain_template_filename,
            out_matrix=affine_transform_filename,
            two_blur=1,
            cost='nmi',
            convergence=convergence,
            two_pass=True,
            center_of_mass='',
            maxrot=90,
            warp_type=warp_type,
            out_file=fname_presuffix(masked_anat_filename, suffix='_aff'),
            environ=environ,
            **verbosity_quietness_kwargs)
        affine_transforms.append(affine_transform_filename)

        # Apply the registration to the whole head
        out_allineate2 = allineate2(
            in_file=unbiased_anat_filename,
            master=head_template_filename,
            in_matrix=affine_transform_filename,
            out_file=fname_presuffix(unbiased_anat_filename,
                                     suffix='_' + warp_type),
            environ=environ,
            **verbosity_quietness_kwargs)
        allineated_filenames.append(out_allineate2.outputs.out_file)
        intermediate_files.extend([unbiased_anat_filename,
                                   masked_anat_filename,
                                   out_allineate.outputs.out_file])

    if registration_kind != 'nonlinear':
        registered = allineated_filenames
        warp_transforms = [None]
    else:
        intermediate_files.extend(allineated_filenames)
        warp_transforms = []
        registered = []
        for allineated_filename in allineated_filenames:
            # Non-linear registration of affine pre-registered whole head image
            # to template. Don't initiate straight from the original with an
            # iniwarp due to weird errors (like it creating an Allin it then can't
            # find)
            # XXX what is the need to the iwarp ?
            if maxlev is not None:
                out_qwarp = qwarp(
                    in_file=allineated_filename,
                    base_file=head_template_filename,
                    weight=dilated_head_mask_filename,
                    nmi=True,
                    noneg=True,
                    blur=[0],
                    maxlev=maxlev,
                    out_file=fname_presuffix(allineated_filename,
                                             suffix='_warped'),
                    environ=environ,
                    **verb_quietness_kwargs)
            else:
                out_qwarp = qwarp(
                    in_file=allineated_filename,
                    base_file=head_template_filename,
                    weight=dilated_head_mask_filename,
                    nmi=True,
                    noneg=True,
                    blur=[0],
                    out_file=fname_presuffix(allineated_filename,
                                             suffix='_warped'),
                    environ=environ,
                    **verb_quietness_kwargs)
    
            registered.append(out_qwarp.outputs.warped_source)
            warp_transforms.append(out_qwarp.outputs.source_warp)
    
    os.chdir(current_dir)
    if not caching:
        for intermediate_file in intermediate_files:
            if os.path.isfile(intermediate_file):
                os.remove(intermediate_file)

    # XXX can't we just catenate the affine to the warp?
    return Bunch(registered=registered,
                 transforms=warp_transforms,
                 pre_transforms=affine_transforms)
